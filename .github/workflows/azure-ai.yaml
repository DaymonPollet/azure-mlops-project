name: Azure ML Job Pipeline # Display name for your workflow in GitHub Actions
on:
  workflow_dispatch: # Allows you to manually trigger the workflow from GitHub UI
  # Uncomment the following block later if you want the workflow to run on every push to 'main'
  # push:
  #   branches:
  #     - main

env:
  GROUP: mlops-demo # 
  WORKSPACE: pollet-daymon-ml 
  LOCATION: westeurope 

jobs:
  azure-pipeline:
    runs-on: ubuntu-24.04 
    steps:
      # 1. Check out code repository: Clones your GitHub repository into the runner
      - name: Check out code repository
        uses: actions/checkout@v4

      # 2. Azure login: Logs into Azure using the Service Principal credentials stored in GitHub Secrets
      - name: Azure login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      # 3. Azure test - Get Compute: (Demonstration step)
      #    Installs Azure ML CLI extension and lists computes to verify connection
      #    This step is directly from your assignment instructions.
      - name: Azure test - Get Compute
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: latest # CHANGED THIS LINE
          inlineScript: |
            az extension add --name ml
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
            az ml compute list
            
      # 4. Azure -- Component Setup (from assignment)
      # Reusing 'latest' for azcliversion
      - name: Azure -- Component Setup
        uses: Azure/CLI@v2.1.0
        with:
          azcliversion: latest
          inlineScript: |
            az extension add --name ml
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
            az ml component create --file ./components/dataprep/dataprep.yaml # Corrected from components to component, if you get an error revert to components
            az ml component create --file ./components/dataprep/data_split.yaml # Corrected from components to component
            az ml component create --file ./components/training/training.yaml # Corrected from components to component

      # 5. Pipeline in Azure - Start the training job (from assignment)
      # Reusing 'latest' for azcliversion
      - name: Azure -- Start Training Job
        uses: Azure/CLI@v2.1.0
        with:
          azcliversion: latest
          inlineScript: |
            az extension add --name ml
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
            az ml job create --file ./pipeline.yaml --stream --set name=animals-classification-${{ github.sha }}-${{ github.run_id }}

      # 6. Stop the compute machine (from assignment)
      # Reusing 'latest' for azcliversion and adding continue-on-error
      - name: Azure -- Stop Compute
        uses: Azure/CLI@v2.1.0
        with:
          azcliversion: latest
          inlineScript: |
            az extension add --name ml -y # Added -y for non-interactive
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
            az ml compute stop --name cli-created-machine
        continue-on-error: true # Ignore errors if compute is already stopped

  download:
      needs: azure-pipeline # New!! This job will only run after 'azure-pipeline' succeeds
      runs-on: ubuntu-24.04
      steps:

      - name: Check out repository
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Azure -- Download Model
        uses: azure/CLI@v2.1.0
        with:
          azcliversion: latest # Use 'latest' as it works for you
          inlineScript: |
            az extension add --name ml -y
            az configure --defaults group=$GROUP workspace=$WORKSPACE location=$LOCATION
            # Get the latest version of the 'animal-classification' model
            VERSION=$(az ml model list -n animal-classification --query "[0].version" -o tsv)
            # Download the model. Assuming it should be downloaded to the current working directory.
            # If your model is in an asset (e.g. zip) you may need to specify the --output-path
            az ml model download --name animal-classification --version $VERSION

      # New!! Uploads the content of the 'inference' directory as an artifact
      - name: Docker -- Upload API code from Inference
        uses: actions/upload-artifact@v4.3.3
        with:
          name: docker-config
          path: inference
      